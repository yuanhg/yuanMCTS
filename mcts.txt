蒙特卡洛搜索树，大体分为四步，选择，扩展，模拟，回传。通过不断重复这四步，也就可以不断扩展这棵搜索树，最后到达时间限制或者到达模拟次数限制之后，最终可以形成一棵不对称的树。由于每个节点记录了选择的次数数据，因此树构建完成后可以选择根节点下一层中选择次数最大的子节点作为落子，因为我们知道，虽然一开始的选择节点是很随机的，但是通过回传操作，节点的价值是不断更新的，因此最终选择次数最多的节点我们认为可能是效果比较好的节点，事实也证明这是完全正确的想法。

1，选择   就是选择一个节点，刚开始时，只有根节点，没有子节点可以选择就跳到下一步，扩展，如果有子节点，就根据子节点的价值抽样选择一个，然后再看选择的这个子节点还有没有子节点，如果有，继续往下选择，直到选择到叶子结点。然后进入下一步。


2，扩展   选择到叶子节点之后，就可以进行扩展，将叶子结点的子节点展开，可以展开一个，也可以展开多个，要根据实际情况而定。比如我们熟知的阿尔法狗算法，每次都展开所有的子节点，然后根据神经网络输出的概率给每个子节点赋值先验概率，这里不多说，感兴趣的去了解阿尔法狗的论文。而正常的MCTS，展开一个的较为常见，其实本质上区别不大，因为我们会记录节点是否已完全展开，没有完全展开的节点，接下来的模拟中会继续展开的，所以本质上展开一个和多个区别不大，因为最终基本都会展开。
3，模拟  这也是MCTS中较为重要的一步，根据一个策略，通常随机策略的效果就非常不错，借用阿尔法狗第一作者David Silver在伦敦大学强化学习课程中说的一句话：不要以为随机策略是很糟糕的策略，它常常可以取得非常不错的效果。  所以这里我们一般就是采用随机策略，从刚才扩展的叶子结点开始一直模拟到游戏结束。具体什么意思呢？就是从这个叶子结点的局面开始，博弈双方都随机的从可用的地方落子一直到比赛胜负，这个胜负的结果一定程度上就反映了了这个局面的情况，如果胜了，至少可以有种落子的方式可以赢一次不是吗，当然我们也能想象到这个结果是很不可靠的，毕竟随机落子的，事实上确实是不可靠的，但是好处就是快，而且我们可以模拟很多次，上千次，这样即使是随机的，如果大部分都是赢的话，也足以说明这个局面的赢面是大的，所以本质上MCTS就是以频率逼近概率的算法。
4，回传   上一步模拟出胜负结果之后，这个结果一般是1，-1和0，代表胜负平，然后把这个结果回传，更新这个路径上的节点的值。举个具体的例子，比如说模拟的结果是胜利，也就是1，那么第二步那个叶子结点的价值就加1，当然还有其他的值需要更新，比如选择的次数也要加1，然后它的父节点的值就要加-1，因为是博弈，对对手是胜利，对自己就是失败，所以取相反数，然后父节点的父节点就是加1，依次递归到根节点，更新整个路径上的节点的值。    到此为止，上面四步完成后，一次蒙特卡洛搜索就结束了，然后在进行第二次，第三次，成百上千次，都结束之后，根据根节点的子节点的选择次数信息，选择计数最大的那一步落子，到这里才算真正的下第一步棋，也就是前面成百上千次的MCTS都只是在脑袋里想想而已，并不是真正的下棋。
井字棋   就是根据上面介绍的MCTS实现自己的东西了，其实重点就是构建这样一棵树，游戏的部分很简单，定义棋盘：一就是定义棋面状态，用一个3*3的2维数据就行了，表示每个位置的落子情况，是圈还是叉还是空白。二是游戏的棋盘状态，需要包含上一步的棋面状态，，这部分你还可以定义一些必要的功能函数，比如游戏是否结束，判断谁是胜者，定义落子函数，获取合法的落子位置等等，这些都是很常见的函数。
定义落子：必要时还可以定义落子类，也就是动作类，包含落子的坐标还有取值，取值就代表圈还是叉，这样游戏落子的很多地方就方便了许多。   
重点是树的构建，这也是对你的数据结构熟练度的考察，你需要首先定义节点类，变量至少要包含必要的价值和计数值，还有记录父节点和子节点的信息，还有上面介绍的一系列操作，选择，扩展，模拟，回传等等。然后在定义蒙特卡洛搜索树类，利用上面的节点类，主要完成树的构建，还有进行多次的模拟，并且还要定义获取最优落子的函数。